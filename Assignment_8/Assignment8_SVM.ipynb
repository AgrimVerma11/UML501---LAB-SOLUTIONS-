{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 8"
      ],
      "metadata": {
        "id": "KHesoeVZ-Lo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Iris dataset is a classic example for demonstrating classification algorithms. It consists of 150 samples of iris flowers belonging to three species: Setosa, Versicolor, and Virginica, with four input features (sepal and petal length/width). Use SVC from sklearn.svm on the Iris dataset and follow the steps below:\n",
        "\n",
        "a) Load the dataset and perform trainâ€“test split (80:20).\n",
        "\n",
        "b) Train three different SVM models using the following kernels:\n",
        "Linear, Polynomial (degree=3), RBF\n",
        "\n",
        "c) Evaluate each model using:\n",
        "-  Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-Score\n",
        "\n",
        "d) Display the confusion matrix for each kernel.\n",
        "\n",
        "e) Identify which kernel performs the best and why."
      ],
      "metadata": {
        "id": "phqZJfAy8X9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import ( ## to just upload everthing together insteaf of writing multiple lines\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hSA1gANh8ELS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sow1CRqR8CuU",
        "outputId": "073a2cf7-7dc8-4d29-e639-277bedc3f8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel: linear\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "\n",
            "Kernel: poly\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "\n",
            "Kernel: rbf\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "\n",
            "Best Kernel:  linear\n"
          ]
        }
      ],
      "source": [
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "kernels = [\"linear\", \"poly\", \"rbf\"]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for kernel in kernels:\n",
        "    if kernel == \"poly\":\n",
        "        model = SVC(kernel=kernel, degree=3)\n",
        "    else:\n",
        "        model = SVC(kernel=kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    results[kernel] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "    }\n",
        "\n",
        "for kernel, metrics in results.items():\n",
        "    print(f\"Kernel: {kernel}\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(metrics[\"confusion_matrix\"])\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"Best Kernel: \", max(results, key=lambda k: results[k][\"accuracy\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM models are highly sensitive to the scale of input features. When features have different ranges, the algorithm may incorrectly assign higher importance to variables with larger magnitudes, affecting the placement of the separating hyperplane. Feature scaling ensures that all attributes contribute equally to distance-based computations, which is especially crucial for kernels like RBF or polynomial.\n",
        "\n",
        "A) Use the Breast Cancer dataset from sklearn.datasets.load_breast_cancer.\n",
        "\n",
        "B) Train an SVM (RBF kernel) model with and without feature scaling (StandardScaler). Compare both results using:\n",
        "- Training accuracy\n",
        "- Testing accuracy\n",
        "\n",
        "C) Discuss the effect of feature scaling on SVM performance."
      ],
      "metadata": {
        "id": "TUdzIB6F8pYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "fKfVKBIW8Wia"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_no_scaling = SVC(kernel=\"rbf\", random_state=42)\n",
        "svm_no_scaling.fit(X_train, y_train)\n",
        "y_train_pred_no_scaling = svm_no_scaling.predict(X_train)\n",
        "y_test_pred_no_scaling = svm_no_scaling.predict(X_test)\n",
        "train_accuracy_no_scaling = accuracy_score(y_train, y_train_pred_no_scaling)\n",
        "test_accuracy_no_scaling = accuracy_score(y_test, y_test_pred_no_scaling)"
      ],
      "metadata": {
        "id": "icjZb39j8zcm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "svm_with_scaling = SVC(kernel=\"rbf\", random_state=42)\n",
        "svm_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_train_pred_with_scaling = svm_with_scaling.predict(X_train_scaled)\n",
        "y_test_pred_with_scaling = svm_with_scaling.predict(X_test_scaled)\n",
        "train_accuracy_with_scaling = accuracy_score(y_train, y_train_pred_with_scaling)\n",
        "test_accuracy_with_scaling = accuracy_score(y_test, y_test_pred_with_scaling)\n"
      ],
      "metadata": {
        "id": "Pvcv7fpE81D6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM without Feature Scaling:\")\n",
        "print(f\"Training Accuracy: {train_accuracy_no_scaling:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy_no_scaling:.4f}\")\n",
        "print(\"\\nSVM with Feature Scaling:\")\n",
        "print(f\"Training Accuracy: {train_accuracy_with_scaling:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy_with_scaling:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maq0Ty8K826A",
        "outputId": "48abb561-6428-4ae2-a2df-cd212799e818"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM without Feature Scaling:\n",
            "Training Accuracy: 0.9143\n",
            "Testing Accuracy: 0.9474\n",
            "\n",
            "SVM with Feature Scaling:\n",
            "Training Accuracy: 0.9890\n",
            "Testing Accuracy: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effect of feature scaling on SVM is - **higher accuracy and faster training times**"
      ],
      "metadata": {
        "id": "K49P-gCI9Pz3"
      }
    }
  ]
}